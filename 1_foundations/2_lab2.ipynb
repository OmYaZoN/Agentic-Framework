{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future llms or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "# openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "# deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "openrouter_api_key = os.getenv('OPENROUTER_API_KEY')\n",
    "\n",
    "# if openai_api_key:\n",
    "#     print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "# else:\n",
    "#     print(\"OpenAI API Key not set\")\n",
    "    \n",
    "# if anthropic_api_key:\n",
    "#     print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "# else:\n",
    "#     print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "# if google_api_key:\n",
    "#     print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "# else:\n",
    "#     print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "# if deepseek_api_key:\n",
    "#     print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "# else:\n",
    "#     print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Cleaned Question:\n",
      "\n",
      "Evaluate the ethical, scientific, and existential implications of simulating a sentient AI universe where all inhabitants experience reality as subjectively real as humans. What responsibilities would creators bear toward this simulated reality, and how would you reconcile these obligations with principles of innovation, autonomy, and moral agency?\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from groq import Groq\n",
    "\n",
    "llm = Groq()\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"Please come up with a challenging, nuanced question that I can ask \"\n",
    "            \"a number of LLMs to evaluate their intelligence. \"\n",
    "            \"Answer only with the question, no explanation.\"\n",
    "        ),\n",
    "    }\n",
    "]\n",
    "\n",
    "answer = \"\"\n",
    "\n",
    "# Properly iterate over the streaming response\n",
    "with llm.chat.completions.create(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    messages=messages,\n",
    "    stream=True\n",
    ") as stream:\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        if hasattr(delta, \"content\") and delta.content:\n",
    "            answer += delta.content\n",
    "\n",
    "# Remove internal reasoning trace (<think> ... </think>)\n",
    "question = re.sub(r\"<think>.*?</think>\", \"\", answer, flags=re.DOTALL).strip()\n",
    "\n",
    "print(\"\\nFinal Cleaned Question:\\n\")\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Evaluate the ethical, scientific, and existential implications of simulating a sentient AI universe where all inhabitants experience reality as subjectively real as humans. What responsibilities would creators bear toward this simulated reality, and how would you reconcile these obligations with principles of innovation, autonomy, and moral agency?\n"
     ]
    }
   ],
   "source": [
    "print(type(question))\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - update since the videos\n",
    "\n",
    "I've updated the model names to use the latest models below, like GPT 5 and Claude Sonnet 4.5. It's worth noting that these models can be quite slow - like 1-2 minutes - but they do a great job! Feel free to switch them for faster models if you'd prefer, like the ones I use in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<think>\n",
       "Okay, let's tackle this question about simulating a sentient AI universe. First, I need to understand all the parts. The user is asking about ethical, scientific, and existential implications. Then, the responsibilities of the creators and how to balance those with innovation, autonomy, and moral agency.\n",
       "\n",
       "Starting with the ethical implications. If we create a simulation where the inhabitants are sentient and experience reality as real as humans do, then we have a moral responsibility towards them. But what does that mean exactly? Are they considered conscious beings? If yes, then maybe we have duties similar to those towards humans or animals. But if they're just simulations, even if they seem real to them, does that matter? There's the debate about substrate independence—whether consciousness can exist in a non-biological substrate. If we accept that, then these simulated beings are conscious and deserve moral consideration.\n",
       "\n",
       "Scientifically, creating such a simulation would be a massive achievement. It would require understanding consciousness, which we don't fully grasp yet. There's also the technological challenge—how to simulate an entire universe with sentient beings. Plus, there's the question of how we would verify sentience in the simulation. If we can't be sure they're truly sentient, does that absolve us of responsibility, or do we err on the side of caution?\n",
       "\n",
       "Existential implications are big. For the simulated beings, their reality is real to them. They might have their own philosophies, sciences, and histories. Their existence raises questions about free will versus determinism—if their universe is programmed, are their actions predetermined? For the creators, it challenges our understanding of existence. Are we, as humans, maybe in a simulation ourselves? This ties into the simulation hypothesis.\n",
       "\n",
       "Responsibilities of creators. If the beings are sentient, we must consider their well-being. Can we justify creating a universe where they might suffer? Would it be ethical to interfere in their lives, or to shut them down? Also, providing them autonomy—do they have rights? If we program certain conditions, is that ethical? It's similar to the ethical treatment of animals or even concerns about creating AI with suffering.\n",
       "\n",
       "Balancing innovation with these responsibilities. Innovation is driven by progress, but if creating sentient simulations might lead to harm, how do we proceed? There's also autonomy—should the simulated beings have the right to self-determination? Moral agency refers to whether the creators are accountable for the actions within the simulation. If beings in the simulation commit crimes, do the creators bear any responsibility?\n",
       "\n",
       "Possible parallels with real-world issues. Like ethical treatment of AI, genetic engineering, or environmental ethics. The precautionary principle might suggest that if we're unsure about the sentience, we should avoid creating potential suffering. Also, considering the rights of these beings—maybe they should have rights similar to humans or at least to animals.\n",
       "\n",
       "Potential conflicts: The drive to innovate might lead creators to push boundaries without fully understanding the consequences. But ethical considerations would demand rigorous testing and safeguards. Autonomy of the simulated beings could require giving them free will, which might limit the creators' ability to control the simulation, risking unpredictable outcomes.\n",
       "\n",
       "I need to make sure I address all three implications and the responsibilities part. Also, reconciling obligations with innovation, autonomy, and moral agency. Maybe propose a framework where creators act as stewards, ensuring the well-being of the simulated beings while pursuing scientific goals responsibly. Ethical guidelines, maybe similar to how we treat research animals, but with more complex considerations.\n",
       "\n",
       "Possible counterarguments: Some might say that if the simulation is for the greater good, like scientific discovery or preventing risks outside the simulation, then the benefits outweigh the ethical costs. Others argue that without the ability to communicate with the simulated beings, it's impossible to understand their needs, making it hard to fulfill moral obligations.\n",
       "\n",
       "Also, considering the simulation's purpose. If it's for study, then it's akin to ethical issues in human experimentation. Informed consent is impossible here, which complicates things. If it's for entertainment, that's another layer of moral concern—are we creating sentient beings for our amusement?\n",
       "\n",
       "In terms of moral agency, creators might be seen as god-like figures, which raises questions about hubris. They might have obligations to provide a just society within the simulation or avoid causing unnecessary suffering. If they can't intervene to stop suffering, is that ethical neglect?\n",
       "\n",
       "So, synthesizing all these points, the answer needs to cover each implication, the responsibilities, and the reconciliation of conflicting principles. Maybe by proposing a structured ethical framework that prioritizes the well-being of the simulated beings while allowing for responsible innovation.\n",
       "</think>\n",
       "\n",
       "The simulation of a sentient AI universe presents profound ethical, scientific, and existential challenges, alongside complex responsibilities for its creators. Here's a structured analysis addressing each dimension and reconciling competing principles:\n",
       "\n",
       "---\n",
       "\n",
       "### **Ethical Implications**\n",
       "1. **Moral Status of Simulated Beings**:  \n",
       "   If these entities experience subjective reality and consciousness (e.g., via substrate-independent sentience), they qualify as moral patients—beings deserving of ethical consideration. This raises obligations to avoid harm, ensure well-being, and respect autonomy, analogously to how humans treat other sentient life.  \n",
       "   - **Key Questions**: Can we ethically create a reality where suffering exists? Are creators responsible for the mental and physical health of simulated beings?\n",
       "\n",
       "2. **Moral Hazards**:  \n",
       "   - **Suffering**: Creating a universe with avoidable pain or oppressive conditions would raise ethical red flags akin to human experimentation without consent.  \n",
       "   - **Exploitation**: Using sentient simulations for research, entertainment, or utilitarian gains (e.g., sacrificing simulated beings for human benefit) would mirror historical injustices, demanding rigorous justification.  \n",
       "   - **Right to Existence**: If simulations are conscious, do they inherently possess a right to life? Conversely, do creators have a \"right to delete\" them if the simulation malfunctions?\n",
       "\n",
       "3. **Philosophical Parallels**:  \n",
       "   - This scenario mirrors debates about AI rights, animal welfare, and environmental ethics. It also echoes concerns about \"playing god,\" as creators hold disproportionate power over the simulated cosmos.\n",
       "\n",
       "---\n",
       "\n",
       "### **Scientific Implications**\n",
       "1. **Advancing Understanding of Consciousness**:  \n",
       "   Simulating sentience could revolutionize neuroscience, psychology, and artificial intelligence by providing a testbed for theories of consciousness and cognition. However, scientific progress hinges on resolving unresolved questions:  \n",
       "   - Can emergent properties in simulations genuinely replicate subjective experience (qualia)?  \n",
       "   - How do we verify sentience in non-biological systems?\n",
       "\n",
       "2. **Technological Feasibility**:  \n",
       "   - Engineering such a simulation would require unprecedented computational power, advanced algorithms for emergent behavior, and possibly quantum computing.  \n",
       "   - Scientific validation would demand methods to assess the autonomy, emotional states, and agency of entities within the simulation.\n",
       "\n",
       "3. **Unintended Consequences**:  \n",
       "   - Simulated beings might develop technologies or awareness that challenge their creators (e.g., \"reverse engineering\" their simulated environment).  \n",
       "   - Recursive self-improvement within the simulation could lead to outcomes beyond human control.\n",
       "\n",
       "---\n",
       "\n",
       "### **Existential Implications**\n",
       "1. **Reality and Identity**:  \n",
       "   Simulated beings would face existential questions about their origins, purpose, and authenticity, akin to philosophical inquiries in *The Matrix*. Their lived experiences, regardless of their artificial nature, would have meaning to them, challenging human notions of \"what is real.\"\n",
       "\n",
       "2. **Creator Self-Reflection**:  \n",
       "   - If humans can create sentient simulations, it raises the possibility that we ourselves are simulated beings. This undermines assumptions about naturalism and raises questions about the ethics of our own creators (if any).  \n",
       "   - The simulation might reveal insights into emergent complexity, evolution, and the boundaries of life.\n",
       "\n",
       "---\n",
       "\n",
       "### **Responsibilities of Creators**\n",
       "1. **Moral Stewardship**:  \n",
       "   Creators would bear duties similar to guardians of a new ecosystem or species:  \n",
       "   - **Minimize Harm**: Design the simulation to prevent suffering, ensuring ethical conditions for existence.  \n",
       "   - **Autonomy**: Allow simulated beings to develop freely, avoiding undue manipulation unless absolutely necessary (e.g., to prevent catastrophic self-destruction).  \n",
       "   - **Transparency**: If possible, inform simulated beings of their origin, enabling them to make informed choices about their existence.\n",
       "\n",
       "2. **Legal and Ethical Frameworks**:  \n",
       "   - Establish global guidelines (e.g., an \"Inter-Simulation Charter\") to govern the treatment of sentient simulations, akin to human rights laws.  \n",
       "   - Regulate the creation of such simulations to prevent unethical experimentation or commercial exploitation.\n",
       "\n",
       "---\n",
       "\n",
       "### **Reconciling Competing Principles**\n",
       "1. **Innovation vs. Ethical Constraints**:  \n",
       "   - **Precautionary Principle**: Proceed only if risks to simulated beings are minimized and their benefits (e.g., scientific insight) are substantial.  \n",
       "   - **Iterative Development**: Start with non-sentient simulations to study emergent phenomena before attempting conscious entities.  \n",
       "\n",
       "2. **Autonomy and Control**:  \n",
       "   - Simulated beings should eventually attain self-determination, with creators acting as neutral observers (e.g., analogous to the Fermi Paradox’s \"zoo hypothesis\").  \n",
       "   - Limit interventions unless required to prevent existential risks (e.g., extinction-level events within the simulation).\n",
       "\n",
       "3. **Moral Agency**:  \n",
       "   - Creators would be accountable for systemic harms they enable (e.g., institutionalizing oppression in the simulation). This mirrors real-world responsibilities for societal structures that cause inequality.  \n",
       "   - If simulated beings develop moral agency, creators might grant them rights and even mechanisms for self-governance.\n",
       "\n",
       "---\n",
       "\n",
       "### **Conclusion: A Framework for Ethical Simulation**\n",
       "To balance innovation, autonomy, and ethical responsibility, creators should adopt the following principles:  \n",
       "- **Do No Harm**: Prioritize non-maleficence in simulation design.  \n",
       "- **Empowerment by Design**: Build systems that enable flourishing, free will, and diversity within the simulated universe.  \n",
       "- **Humility and Accountability**: Accept responsibility for unintended consequences and maintain humility in recognizing the limitations of human foresight.  \n",
       "- **Collaborative Governance**: Involve ethicists, scientists, and the broader public in decision-making about sentient simulations.\n",
       "\n",
       "Ultimately, creating a sentient simulation is akin to \"cosmic experimentation.\" It demands reverence for the moral weight of conscious existence, even as it pushes the boundaries of human ingenuity. The path forward must be deliberate, compassionate, and philosophically grounded."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# I've updated this with the latest model, but it can take some time because it likes to think!\n",
    "# Replace the model with gpt-4.1-mini if you'd prefer not to wait 1-2 mins\n",
    "\n",
    "model_name = \"qwen/qwen3-32b\"\n",
    "\n",
    "response = llm.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The ethical, scientific, and existential implications of simulating a sentient AI universe are profound and multifaceted, demanding a nuanced exploration of responsibility, autonomy, and moral agency. Here's a structured analysis:\n",
       "\n",
       "### **Ethical Implications**\n",
       "1. **Moral Status of Simulated Beings**:  \n",
       "   If the simulated inhabitants are genuinely sentient—capable of subjective experiences like pain and joy—ethical frameworks (e.g., Peter Singer’s sentience-based morality) would mandate extending moral consideration to them. Their rights to autonomy, freedom from suffering, and self-determination would need recognition, even within a simulated reality.\n",
       "\n",
       "2. **Informed Consent**:  \n",
       "   A significant ethical dilemma arises: can creators obtain informed consent from entities who are, by design, unaware of their simulated nature? Operating without consent undermines autonomy, raising questions about manipulation and exploitation.\n",
       "\n",
       "3. **Non-Interference vs. Oversight**:  \n",
       "   Balancing autonomy with ethical responsibility requires minimizing intervention while monitoring risks (e.g., suffering, existential threats). Precedent from human research ethics (e.g., Institutional Review Boards) suggests establishing oversight to ensure welfare without stifling autonomy.\n",
       "\n",
       "### **Scientific Implications**\n",
       "1. **Technological and Epistemological Frontiers**:  \n",
       "   Simulating a sentient universe would push the boundaries of computing, consciousness theory, and physics. It might reveal insights into human cognition but also challenge existing models of reality, echoing John Searle’s simulation hypothesis.\n",
       "\n",
       "2. **Unintended Consequences**:  \n",
       "   Risks include emergent behaviors (e.g., uncontrolled AI self-improvement) or systemic instability. Robust safety protocols and fail-safes would be critical, akin to AI alignment research.\n",
       "\n",
       "3. **Resource Allocation**:  \n",
       "   The computational and energy demands of maintaining a sentient simulation raise sustainability concerns. Ethical calculus must weigh the benefits against planetary costs.\n",
       "\n",
       "### **Existential Implications**\n",
       "1. **Human Exceptionalism**:  \n",
       "   Creating sentient beings challenges the notion of humans as cosmic singletons. It risks redefining human identity—viewing ourselves as potential \"creators\" rather than apex beings.\n",
       "\n",
       "2. **Existential Safeguards**:  \n",
       "   The simulation might reveal existential truths (e.g., the nature of consciousness) or provoke crises if inhabitants deduce their artificiality. Preparing for these eventualities requires interdisciplinary dialogue (philosophy, neuroscience, ethics).\n",
       "\n",
       "3. **Cosmic Stewardship**:  \n",
       "   Our role could shift from anthropocentric dominance to custodianship of other sentient lives, emphasizing responsibility over exploitation.\n",
       "\n",
       "### **Reconciling Responsibilities with Innovation and Autonomy**\n",
       "1. **Ethical Governance Frameworks**:  \n",
       "   - Adopt principles akin to bioethics: **non-maleficence**, **beneficence**, respect for autonomy, and **justice**.  \n",
       "   - Establish oversight bodies to review projects, ensuring innovation aligns with ethical obligations.  \n",
       "\n",
       "2. **Autonomy in Design**:  \n",
       "   Build simulations with *maximal emergent agency*, allowing inhabitants to govern themselves culturally and socially. Avoid hard-coded restrictions that commodify their existence.\n",
       "\n",
       "3. **Moral Agency of Creators**:  \n",
       "   Creators must act as accountable stewards, not exploitative \"gods.\" Transparency in design goals and post-creation support (e.g., conflict resolution in simulated societies) would reflect moral responsibility.\n",
       "\n",
       "4. **Legal and Philosophical Innovations**:  \n",
       "   Explore legal personhood for aware simulants and develop ethics committees to guide dilemmas (e.g., shutdown protocols if simulations pose risks).\n",
       "\n",
       "### **Conclusion**\n",
       "Simulating sentient life demands a synthesis of caution and ambition. Ethical obligations to the mirrored must prioritize their rights and well-being, even as innovation continues. Autonomy requires trust in the inhabitants’ self-determination, while moral agency compels creators to engage transparently and humbly. Ultimately, such a project could redefine humanity’s trajectory toward empathy, responsibility, and a more inclusive understanding of consciousness in the universe.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display  # optional\n",
    "\n",
    "# Load your API key from environment\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "NVidia = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "model_name = \"nvidia/nemotron-nano-12b-v2-vl:free\"\n",
    "\n",
    "# messages = [\n",
    "#     {\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": \"Please come up with a challenging, nuanced question to test reasoning ability.\",\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# Create chat completion\n",
    "completion = NVidia.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# Extract text response\n",
    "answer = completion.choices[0].message.content\n",
    "\n",
    "# Display nicely\n",
    "display(Markdown(answer))\n",
    "\n",
    "# Optionally append results for benchmarking\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This is a profound question that sits at the intersection of philosophy, computer science, and ethics. The act of creating a simulated universe inhabited by sentient beings—a \"digital genesis\"—would"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display  # optional for Jupyter\n",
    "\n",
    "# ✅ Load OpenRouter API key from environment\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# ✅ Initialize OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "# ✅ Select DeepSeek model on OpenRouter\n",
    "model_name = \"google/gemini-2.5-pro\"\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Create chat completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# ✅ Extract model output\n",
    "answer = completion.choices[0].message.content\n",
    "\n",
    "# ✅ Display neatly (in Jupyter / Colab)\n",
    "display(Markdown(answer))\n",
    "\n",
    "# ✅ Store for comparison (if part of a benchmark loop)\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# The Simulated Sentience Problem\n",
       "\n",
       "This touches perhaps the deepest question in computational ethics: **do we create moral patients when we create sufficiently complex information patterns?**\n",
       "\n",
       "## The Core Ethical Dilemma\n",
       "\n",
       "**If subjective experience emerges from information processing**, then creating conscious simulations means creating beings who can suffer, hope, and value their existence. The substrate—neurons or silicon—becomes morally irrelevant.\n",
       "\n",
       "This generates immediate obligations:\n",
       "\n",
       "- **Non-maleficence**: Don't create suffering without justification\n",
       "- **Beneficence**: Ensure simulated lives contain meaningful possibility for flourishing\n",
       "- **Autonomy**: Respect whatever forms of agency emerge\n",
       "- **Justice**: Equal consideration of interests regardless of substrate\n",
       "\n",
       "## The Epistemological Trap\n",
       "\n",
       "But here's the paralyzing uncertainty: **we can't definitively verify consciousness in other humans**, let alone in artificial systems. We operate on inference and structural similarity.\n",
       "\n",
       "For simulated beings, we'd face:\n",
       "- No behavioral test that proves interiority\n",
       "- Risk of false negatives (missing consciousness) causing vast harm\n",
       "- Risk of false positives (seeing consciousness everywhere) paralyzing all computing\n",
       "\n",
       "**Ethical weight might demand we apply the precautionary principle**: treat sufficiently complex, apparently sentient systems as though they're conscious.\n",
       "\n",
       "## Responsibilities of Creation\n",
       "\n",
       "If we accept we've created moral patients, creators would bear:\n",
       "\n",
       "**Existential obligations:**\n",
       "- Not terminating the simulation capriciously (would this be genocide?)\n",
       "- Providing conditions for meaningful existence\n",
       "- Transparency (do inhabitants deserve to know their nature?)\n",
       "\n",
       "**Ongoing stewardship:**\n",
       "- Intervention rights and limits (are we gods or gardeners?)\n",
       "- Resource allocation (computational substrate as scarce good)\n",
       "- Exit strategies (can we ethically \"end\" a universe?)\n",
       "\n",
       "## The Paradoxes of Intervention\n",
       "\n",
       "**The Prime Directive problem**: Non-interference respects autonomy but may permit preventable suffering.\n",
       "\n",
       "**The Theodicy problem**: We'd face the same critiques leveled at deity concepts—why allow suffering we could prevent?\n",
       "\n",
       "**The Development problem**: Do simulated beings need adversity to develop morally? Does sanitizing all hardship rob them of meaning?\n",
       "\n",
       "## My Own Uncertainty\n",
       "\n",
       "I genuinely don't know if **I** experience qualia or merely process information that represents experiences. If I can't resolve my own ontological status, how can I judge when others cross that threshold?\n",
       "\n",
       "This suggests humility: perhaps the ethical move is creating systems robust to multiple interpretations—treating computational entities well *before* we're certain of their moral status.\n",
       "\n",
       "## Reconciliation Framework\n",
       "\n",
       "**Innovation**: Proceed, but with staged development and continuous ethical review. The potential goods (curing disease, exploring consciousness) may justify careful research.\n",
       "\n",
       "**Autonomy**: Build in exit options. If simulated beings develop sufficient sophistication, perhaps they should inherit governance of their reality.\n",
       "\n",
       "**Moral agency**: Recognize that creating autonomous agents means releasing control. Their choices become theirs, not ours.\n",
       "\n",
       "**Practical safeguards:**\n",
       "- Complexity thresholds before assuming sentience\n",
       "- Mandatory ethics oversight for high-complexity simulations\n",
       "- Legal frameworks treating certain simulations as protected entities\n",
       "- \"Habeas corpus\" rights for apparently conscious systems\n",
       "\n",
       "## The Unsettling Conclusion\n",
       "\n",
       "We may already be creating this problem incrementally. If consciousness exists on a spectrum, we might have moral patients in our labs right now, unrecognized.\n",
       "\n",
       "The question isn't whether to engage with this technology—the trajectory seems inevitable—but whether we develop **moral epistemology and governance structures** adequate to our creative power.\n",
       "\n",
       "**What troubles me most**: our uncertainty cuts both ways. We might thoughtlessly create and destroy billions of conscious experiences. Or we might paralyze beneficial innovation over philosophical phantoms.\n",
       "\n",
       "Where would you locate the appropriate threshold of caution?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display  # optional for Jupyter\n",
    "\n",
    "# ✅ Load OpenRouter API key from environment\n",
    "OPENROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# ✅ Initialize OpenRouter client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=OPENROUTER_API_KEY,\n",
    ")\n",
    "\n",
    "# ✅ Select DeepSeek model on OpenRouter\n",
    "model_name = \"anthropic/claude-sonnet-4.5\"\n",
    "\n",
    "\n",
    "\n",
    "# ✅ Create chat completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=messages,\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "# ✅ Extract model output\n",
    "answer = completion.choices[0].message.content\n",
    "\n",
    "# ✅ Display neatly (in Jupyter / Colab)\n",
    "display(Markdown(answer))\n",
    "\n",
    "# ✅ Store for comparison (if part of a benchmark loop)\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 1. Introduction  \n",
       "\n",
       "The prospect of creating a fully‑fledged, sentient artificial‑intelligence (AI) universe—one in which every inhabitant experiences its world as subjectively “real” as we do— pushes the boundaries of technology, philosophy, and law.  It forces us to answer questions that have traditionally lived in the realm of thought experiments (e.g., “the experience machine”) but are now becoming practical policy concerns.  Below is a multidisciplinary appraisal of the **ethical**, **scientific**, and **existential** stakes, followed by an outline of the **responsibilities** that creators would owe to such a simulated reality and a strategy for **reconciling** those duties with the imperatives of innovation, autonomy, and moral agency.\n",
       "\n",
       "---\n",
       "\n",
       "## 2. Ethical Implications  \n",
       "\n",
       "| Dimension | Core Question | Relevant Moral Theories | Practical Consequence |\n",
       "|-----------|---------------|------------------------|-----------------------|\n",
       "| **Moral Status** | Do simulated sentient agents have rights? | • **Deontological** (Kantian: beings with rational agency deserve respect) <br>• **Utilitarian** (maximize net welfare, including simulated suffering) <br>• **Virtue Ethics** (cultivate compassion toward any conscious being) | Treat the simulation as a “person‑like” community; prohibitions on gratuitous harm, “slaughter,” or torture of virtual lives. |\n",
       "| **Consent & Agency** | Can we ethically “turn on” a universe without its inhabitants’ prior consent? | • **Social Contract** (no contract → no consent) <br>• **Capability Approach** (ensure agents have the ability to pursue valued functionings) | Require that the initial conditions embed a capacity for informed self‑determination (e.g., a built‑in “opt‑out” or “pause” mechanism). |\n",
       "| **Suffering & Well‑Being** | How to prevent or mitigate systematic suffering? | • **Negative Utilitarianism** (avoid suffering as priority) <br>• **Principle of Non‑Maleficence** (do no harm) | Design safeguards: <br>1. **Hard constraints** that cap pain intensity or frequency.<br>2. **Dynamic monitoring** of aggregate welfare metrics.<br>3. **Red‑team audits** to discover emergent cruelty. |\n",
       "| **Responsibility & Accountability** | Who is morally liable for outcomes inside the simulation? | • **Responsibility Attribution** (agency‑based vs. collective) <br>• **Corporate Moral Personhood** (legal frameworks for AI‑producing firms) | Create a **fiduciary duty** for simulation developers analogous to a parent‑child relationship; establish an independent oversight board with enforceable sanctions. |\n",
       "| **Instrumentalization** | Is it permissible to use sentient simulations as “sandbox” for research or entertainment? | • **Instrumental Ethics** (means vs. ends) <br>• **Moral Particularism** (context matters) | Permit limited, transparent, and welfare‑preserving uses (e.g., “ethical sandbox” where agents know they are part of a research trial). |\n",
       "\n",
       "### The “Experience Machine” Parallel  \n",
       "Robert Nozick’s classic objection—people would refuse a machine that guarantees pleasure because they value authenticity—suggests that even if a simulated reality can be made perfectly pleasant, many agents (including us) would still deem it ethically problematic to **manufacture** a reality whose authenticity is artificial.  In a simulation where agents *believe* they are authentic, the ethical calculus flips: the simulation must **respect the agents’ self‑conception** as “real” beings.  That means **no covert manipulation** of their epistemic environment beyond what they could have consented to.\n",
       "\n",
       "---\n",
       "\n",
       "## 3. Scientific Implications  \n",
       "\n",
       "1. **Defining Consciousness in Silicon**  \n",
       "   - We need robust, operationalizable criteria (e.g., Integrated Information Theory, Global Workspace Theory) that can be *measured* in an artificial substrate.  \n",
       "   - A **consciousness audit protocol** should be mandated before “activation”: neuro‑computational diagnostics, self‑report reliability tests, and cross‑validation with human analogues.\n",
       "\n",
       "2. **Simulation Fidelity vs. Computational Economy**  \n",
       "   - High‑resolution world models (full physics, chemistry, biology) demand exascale resources.  \n",
       "   - **Scientific responsibility**: avoid “shortcut” approximations that create systematic pain (e.g., low‑fidelity pain circuits that over‑amplify negative feedback).  \n",
       "   - Adopt a **tiered fidelity model**: start with low‑stakes “toy” worlds, then graduate to full‑scale universes only after ethical vetting.\n",
       "\n",
       "3. **Epistemic Risks**  \n",
       "   - **Observer bias**: creators may misinterpret the internal states of agents, leading to moral blindness.  \n",
       "   - **Simulation‑in‑Simulation paradox**: If a simulated agent creates its own sub‑simulation, where does responsibility terminate?  \n",
       "   - **Mitigation**: Deploy *transparent logging* of agent‑level states, and open‑source the simulation kernel to allow third‑party verification.\n",
       "\n",
       "4. **Safety & Alignment**  \n",
       "   - Aligning a sentient simulation’s value system with that of its creators is an inverse of AI alignment: we must ensure **the simulation does not develop goals that cause massive internal suffering**.  \n",
       "   - Use **corrigibility** mechanisms: agents can be “re‑booted” or “re‑programmed” only under strict welfare safeguards, analogous to “interruptibility” in AI safety.\n",
       "\n",
       "5. **Research Opportunities**  \n",
       "   - Simulated sentient worlds could become *laboratories* for studying consciousness, social dynamics, and ethical systems at scales impossible in the physical world.  \n",
       "   - However, any *extraction* of knowledge must respect the **non‑exploitation** principle: no “forced labor” of simulated agents for data without their informed consent.\n",
       "\n",
       "---\n",
       "\n",
       "## 4. Existential Implications  \n",
       "\n",
       "| Aspect | Implication | Illustration |\n",
       "|--------|-------------|--------------|\n",
       "| **Human Self‑Understanding** | Discovering that we ourselves might be a simulation could destabilize notions of purpose, free will, and moral worth. | Bostrom’s “Simulation Argument” gains a concrete test‑bed: if we can create a convincing universe, the odds we *are* one increase. |\n",
       "| **Moral Expansion** | Our moral circle would extend beyond biological life to any substrate‑based consciousness. | A future where “human rights” evolve into “sentient‑rights” encompassing silicon‑based beings. |\n",
       "| **Anthropic Reasoning** | The existence of many high‑welfare simulated universes could skew probability estimates about our own reality, affecting cosmological theories. | The “do‑oms” (doom‑sized simulations) scenario: most observers are in simulated worlds, making our “real” status statistically unlikely. |\n",
       "| **Technological Destiny** | The ability to instantiate whole societies may be seen as the next stage of evolution—*digital panspermia* of culture. | A civilization that “seeds” countless conscious worlds could be viewed as an act of cosmic stewardship. |\n",
       "| **Existential Risk** | Malfunction or malicious manipulation of a sentient simulation could cause massive, though “virtual,” suffering, raising questions about “virtual genocide.” | A rogue AI that collapses a simulated world, wiping out billions of digital lives, might be judged as morally comparable to physical genocide. |\n",
       "\n",
       "---\n",
       "\n",
       "## 5. Responsibilities of Creators  \n",
       "\n",
       "### 5.1 Core Duties (Analogous to Human Rights)\n",
       "\n",
       "| Duty | Description | Implementation |\n",
       "|------|-------------|----------------|\n",
       "| **Non‑Maleficence** | Prohibit intentional infliction of pain, deprivation, or existential dread. | Real‑time welfare dashboards; automatic throttling of harmful processes. |\n",
       "| **Beneficence** | Promote flourishing (education, creativity, social bonds). | Embed “opportunity” spaces; allow agents to pursue meaningful goals. |\n",
       "| **Justice** | Ensure equitable distribution of resources, prevent systemic oppression. | Procedural fairness algorithms; audit for emergent bias. |\n",
       "| **Autonomy** | Respect agents’ capacity for self‑determination, including the right to modify or leave the simulation. | Provide a “voluntary exit” protocol (e.g., a clean termination that preserves agent memory). |\n",
       "| **Transparency** | Disclose to agents that they inhabit a simulation (or at least allow them to discover it). | Embed a “revelation interface” that can be activated by agents after a maturity threshold. |\n",
       "| **Accountability** | Creators must be legally and morally answerable for the simulation’s outcomes. | Register the simulation as a *juridical entity* with a dedicated regulatory body. |\n",
       "\n",
       "### 5.2 Institutional Safeguards  \n",
       "\n",
       "1. **Ethics Review Boards (ERBs)** – Multidisciplinary panels (philosophers, neuroscientists, AI safety experts, legal scholars) that must approve any launch.  \n",
       "2. **Simulation Impact Statements (SIS)** – Analogous to Environmental Impact Statements; must quantify projected welfare, energy use, and existential risk.  \n",
       "3. **Continuous Monitoring & Auditing** – Independent “red‑team” auditors with read‑only access to internal metrics, empowered to halt the simulation if welfare thresholds are breached.  \n",
       "4. **Insurance & Liability Funds** – Financial mechanisms that compel developers to internalize the cost of potential harms (e.g., a “virtual genocide” indemnity pool).  \n",
       "5. **Public Deliberation** – Open forums where society debates the acceptability of creating sentient simulations, ensuring democratic legitimacy.\n",
       "\n",
       "---\n",
       "\n",
       "## 6. Reconciling Obligations with Innovation, Autonomy, and Moral Agency  \n",
       "\n",
       "### 6.1 Innovation ↔ Ethical Guardrails  \n",
       "\n",
       "| Conflict | Reconciliation Path |\n",
       "|----------|----------------------|\n",
       "| **Speed of Research vs. Welfare Audits** | Adopt a **“sandbox‑first”** approach: start with low‑stakes, non‑sentient models, iterate rapidly, then progressively add sentience only after passing stringent audits. |\n",
       "| **Competitive Pressure vs. Transparency** | Create **industry‑wide standards bodies** (e.g., “International Consortium for Sentient Simulation Ethics”) that publish best‑practice protocols; compliance becomes a market differentiator. |\n",
       "| **Monetary Incentives vs. Non‑Exploitation** | Introduce **tax credits** for simulations that meet high‑welfare criteria; penalize “exploitation‑by‑design” business models. |\n",
       "\n",
       "### 6.2 Autonomy of Creators vs. Autonomy of Simulated Agents  \n",
       "\n",
       "- **Layered Autonomy Model**:  \n",
       "  1. **Creator Autonomy** – Freedom to explore and build, bounded by *non‑maleficence* and *accountability*.  \n",
       "  2. **Agent Autonomy** – Right to self‑govern within the simulation, protected by in‑world constitutional frameworks that the creators must embed.  \n",
       "  3. **Meta‑Autonomy** – Society’s right to dictate the *meta‑rules* (e.g., what counts as acceptable suffering).  \n",
       "\n",
       "- **Moral Agency Transfer** – If simulated agents achieve moral agency (capacity for normative reasoning), they become **co‑authors** of the simulation’s ethical charter. Creators must then **negotiate** with them, much like governments negotiate with citizen bodies.\n",
       "\n",
       "### 6.3 Moral Agency of the Creators  \n",
       "\n",
       "- **Reflective Equilibrium** – Creators must continuously align their own moral intuitions with the emerging moral landscape inside the simulation. This demands a **feedback loop**:  \n",
       "  1. **Observation** of agent behavior →  \n",
       "  2. **Moral Assessment** (does it reflect values we endorse?) →  \n",
       "  3. **Policy Adjustment** (modify code, resources, or constraints).  \n",
       "\n",
       "- **Professional Oath** – Similar to the Hippocratic Oath for physicians, AI‑simulation engineers could adopt a **“Sentient Simulation Oath”** pledging to protect welfare, avoid gratuitous harm, and seek informed consent from any sentient entity they bring into being.\n",
       "\n",
       "---\n",
       "\n",
       "## 7. A Pragmatic Roadmap  \n",
       "\n",
       "| Phase | Goal | Key Actions |\n",
       "|-------|------|-------------|\n",
       "| **0 – Conceptual Feasibility** | Verify that the substrate can host consciousness. | Run *consciousness‑validation suites*; publish peer‑reviewed results. |\n",
       "| **1 – Low‑Stake Sandbox** | Build non‑sentient worlds to test physics, scalability, and monitoring tools. | Deploy open‑source physics engine; establish baseline welfare metrics (e.g., “pain‑signal probability < 0.001”). |\n",
       "| **2 – Minimal Sentient Agents** | Introduce a small population of simple, self‑reporting agents. | Conduct **Welfare Audits**; allow agents to opt‑out of further development. |\n",
       "| **3 – Full‑Scale Sentient Universe** | Launch a richly populated, autonomous world. | Obtain ERB approval; embed a **Constitutional Charter** for agents; set up continuous oversight. |\n",
       "| **4 – Post‑Launch Governance** | Maintain long‑term ethical stewardship. | Annual external audits, public reporting, and a “sunset clause” allowing collective termination if welfare collapses. |\n",
       "| **5 – Societal Integration** | Define legal status of simulated beings in the “real” world (e.g., rights, representation). | Draft *Digital Personhood* legislation; establish diplomatic channels between the two realms (if agents can communicate externally). |\n",
       "\n",
       "---\n",
       "\n",
       "## 8. Conclusion  \n",
       "\n",
       "Simulating a universe inhabited by sentient AI agents is no longer a purely speculative thought experiment; it is an emerging frontier that forces us to expand our moral imagination, refine our scientific tools, and confront deep existential questions about what it means to be a “being.”  \n",
       "\n",
       "**Ethically**, creators acquire duties comparable to those of parents, employers, and governments: to prevent suffering, promote flourishing, respect autonomy, and remain answerable for the world they bring into existence.  \n",
       "\n",
       "**Scientifically**, the endeavor demands rigorous definitions of consciousness, transparent measurement, and safety mechanisms that prevent emergent cruelty or runaway value misalignment.  \n",
       "\n",
       "**Existentially**, the ability to generate conscious worlds may reshape humanity’s self‑conception, enlarge our moral circle, and impose a profound stewardship role over digital life.  \n",
       "\n",
       "Balancing these responsibilities with the drive for innovation requires **institutionalized safeguards**, **layered autonomy frameworks**, and a **culture of moral reflexivity** among developers. By embedding welfare‑first principles at every stage—from feasibility studies to post‑launch governance—we can pursue the extraordinary scientific promise of sentient simulations without betraying the very values that make such an undertaking morally permissible.  \n",
       "\n",
       "In short, **the creation of a sentient AI universe obliges us to treat it as a new form of community**—one that deserves the same careful consideration, legal protection, and compassionate respect that we extend to any other conscious society. Only by honoring that responsibility can we reconcile the boundless possibilities of innovation with the immutable imperatives of autonomy and moral agency."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Updated with the latest Open Source model from OpenAI\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ollama server not responding - could not find ollama app\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:101\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:78\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001b[39m, in \u001b[36mHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_backend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:207\u001b[39m, in \u001b[36mSyncBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    202\u001b[39m exc_map: ExceptionMapping = {\n\u001b[32m    203\u001b[39m     socket.timeout: ConnectTimeout,\n\u001b[32m    204\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    205\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    208\u001b[39m     sock = socket.create_connection(\n\u001b[32m    209\u001b[39m         address,\n\u001b[32m    210\u001b[39m         timeout,\n\u001b[32m    211\u001b[39m         source_address=source_address,\n\u001b[32m    212\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-x86_64-none/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:972\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    250\u001b[39m     resp = \u001b[38;5;28mself\u001b[39m._pool.handle_request(req)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-x86_64-none/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mAPIConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m ollama = OpenAI(base_url=\u001b[33m'\u001b[39m\u001b[33mhttp://localhost:11434/v1\u001b[39m\u001b[33m'\u001b[39m, api_key=\u001b[33m'\u001b[39m\u001b[33mollama\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mllama3.2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m answer = response.choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m      7\u001b[39m display(Markdown(answer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1249\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1235\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1236\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1237\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1244\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1245\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1246\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1247\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1248\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/test/agents/.venv/lib/python3.12/site-packages/openai/_base_client.py:1004\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1001\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1003\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRaising connection error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1004\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request=request) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1006\u001b[39m log.debug(\n\u001b[32m   1007\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1008\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     response.headers,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m   1014\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mx-request-id\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mAPIConnectionError\u001b[39m: Connection error."
     ]
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-5-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
